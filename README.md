# Federated Learning Security Analysis

This repository is split into 4 key sub-directories (3 of which are submodules).

## Table of Contents

- [federated-learning-dlg-example](https://github.com/harrysharma1/federated-learning-dlg-example/tree/884b9a62deac353a49ea6e9e530d853e27873e7f): This repository contains an example script that has minor alterations from the original Deep Leakage as validation that it does indeed work[^1].
- [federated-learning-research-results](https://github.com/harrysharma1/federated-learning-research-results/tree/1e5092b217645596ddde3670ca374a2acc36a78e): This respository contains 4 Jupyter scripts performing the experiments covered within the paper[^1][^2][^3][^4][^5][^6].
- [federated-learning-web-app](https://github.com/harrysharma1/federated-learning-web-app/tree/c809ea88e2ecc83cadcc7249a58fed039a140117): This repository contains the Flask web application as a development build to try out locally (no deployed version as of yet)[^1][^2][^3].
- [web_app_design](https://github.com/harrysharma1/federated-learning-web-app/tree/c809ea88e2ecc83cadcc7249a58fed039a140117): This contains initial Figma files of the web applications UI/UX and a final PDF showcasing the general design of the final project's web application section.
## Acknowledgements and Citations
## Acknowledgements
I would like to thank my supervisor Dr Ruba Abu-Salma alongside Neil Majithia and Calum Inverarity from the Open Data Institute for helping me throughout this research project.

### Citations
Though most of the code is cited, this is included in case there was any missed piece of code that may not have been cited.

[^1]: L. Zhu, Z. Liu, and S. Han, “Deep Leakage from Gradients,” 2019. [Online]. Available: https://arxiv.org/pdf/1906.08935
[^2]: K. A. Bonawitz et al., “Practical Secure Aggregation for Federated Learning on User-Held Data,” CoRR, vol. abs/1611.04482, 2016, [Online]. Available: http://arxiv.org/abs/1611.04482
[^3]: C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating Noise to Sensitivity in Private Data Analysis,” in Theory of Cryptography, 2006, pp. 265–284.
[^4]: FlowerAI, Get started with Flower. 2024. [Online]. Available: https://flower.ai/docs/framework/tutorial-series-get-started-with-flower-pytorch.html
[^5]: FlowerAI, flower/examples/fl-dp-sa/fl_dp_sa at main · adap/flower — github.com. https://github.com/adap/flower/tree/main/examples/fl-dp-sa/fl_dp_sa, 2024. [Online]. Available: https://github.com/adap/flower/tree/main/examples/fl-dp-sa/fl_dp_sa
[^6]: FlowerAI, flower/examples/flower-secure-aggregation/secaggexample at main · adap/flower — github.com. https://github.com/adap/flower/tree/main/examples/flower-secure-aggregation/secaggexample, 2024. [Online]. Available: https://github.com/adap/flower/tree/main/examples/flower-secure-aggregation/secaggexample 
